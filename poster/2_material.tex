　我々はまず、前立腺の病理画像をGP（Gleason pattern）に応じて正常腺管、GP3、GP4、GP5のセマンティックセグメンテーション（Semantic segmentation、画像を意味に基づいてピクセル単位で区分する手法）を行うU-Net\cite{unet}モデルを作成した。U-NetモデルのエンコーダーはVGG16\cite{vgg}を使用し、さらに転移学習を行っている\cite{ternausnet}。デコーダーには逆畳込みではなくNearest samplingを用いた。\par

\vspace{0.5zh}

　モデルは当教室で診断された前立腺全摘出標本とFig\ref{fig:seg_color}のようなラベル付けによって訓練した。モデルの出力例をFig\ref{fig:dl_sample}に示す。\par

\vspace{-1zh}

\begin{figure}[htbp]\centering
  \begin{tabular}{c}
    \begin{subfigure}[t]{0.16\columnwidth}\centering
      \includegraphics[width=0.7\columnwidth]{assets/gp_pin.png}
      \subcaption{正常腺管:黒}
    \end{subfigure}

    \begin{subfigure}[t]{0.16\columnwidth}\centering
      \includegraphics[width=0.7\columnwidth]{assets/gp_3_2.png}
      \subcaption{GP3:青}
    \end{subfigure}

    \begin{subfigure}[t]{0.16\columnwidth}\centering
      \includegraphics[width=0.7\columnwidth]{assets/gp_4.png}
      \subcaption{GP4:緑}
    \end{subfigure}

    \begin{subfigure}[t]{0.16\columnwidth}\centering
      \includegraphics[width=0.7\columnwidth]{assets/gp_5_2.png}
      \subcaption{GP5:赤}
    \end{subfigure}

    \begin{subfigure}[t]{0.16\columnwidth}\centering
      \includegraphics[width=0.7\columnwidth]{assets/gp_3_1.png}
      \subcaption{GP3+4}
    \end{subfigure}

    \begin{subfigure}[t]{0.16\columnwidth}\centering
      \includegraphics[width=0.7\columnwidth]{assets/gp_5_1.png}
      \subcaption{GP4+5}
    \end{subfigure}
  \end{tabular}
  \label{fig:example}
  \caption{セグメンテーションによる色分け例}
  \label{fig:seg_color}
\end{figure}

\begin{figure}[htbp]\centering
  \begin{tabular}{c}
    \begin{subfigure}[t]{0.33\columnwidth}\centering
      \includegraphics[width=0.9\columnwidth]{assets/ex_org.png}
      \subcaption{入力画像}
    \end{subfigure}

    \begin{subfigure}[t]{0.33\columnwidth}\centering
      \includegraphics[width=0.9\columnwidth]{assets/ex_gt.png}
      \subcaption{ラベル画像}
    \end{subfigure}

    \begin{subfigure}[t]{0.33\columnwidth}\centering
      \includegraphics[width=0.9\columnwidth]{assets/ex_pr.png}
      \subcaption{出力画像}
    \end{subfigure}
  \end{tabular}
  \label{fig:example}
  \caption{U-Netモデルによる出力例}
  \label{fig:dl_sample}
\end{figure}

　作成したU-NetモデルのJaccard index(\ref{eq:iou})によって算出したIoU（Intersection over union）は、訓練画像に対して0.765、学習に含めなかったテスト画像に対して0.737であった。

\begin{align}
  \label{eq:iou}
  Jaccard\,index = & \; \frac{|PR \cap GT|}{|PR \cup GT|} \\[5mm]
  PR: \mbox{予測領域(Prediction)} & \;\; GT: \mbox{正解ラベル(Ground truth)} \nonumber
\end{align}

\vspace{0.5zh}

　さらに、USBカメラから入力された画像をHTTPによってネットワーク経由で送信するクライアントアプリケーションと、受信した画像をDLによって解析しその結果を配信するサーバーアプリケーションを作成した(Fig\ref{fig:arch})。前者は顕微鏡カメラとUSB接続したRaspberry Pi 4 Model Bに、後者はDLの動作するコンピュータにそれぞれ導入した。\par

\vspace{1zh}

\begin{figure}\centering
  \includegraphics[width=\columnwidth]{assets/arch.png}
  \caption{クライアント・サーバーアプリケーション構成図}
  \label{fig:arch}
\end{figure}

　クライアントアプリケーションはUSBカメラの映像をGstreamerを用いてリアルタイムで表示する。ユーザーの操作により任意のタイミングの映像のスナップショット画像をサーバーに送信し、結果を確認することができる。
